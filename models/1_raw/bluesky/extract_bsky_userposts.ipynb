{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atproto import Client\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import time\n",
    " \n",
    "# write a chunk of post-data to CSV\n",
    "def write_chunk(df: str, target_user: str) -> None:\n",
    "    # filename format is <username>_<earliest_contained_post_date>_<latest_contained_post_date>\n",
    "    start    = df['post_created_at'].min().to_pydatetime().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    end      = df['post_created_at'].max().to_pydatetime().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    dir = f\"usr_{target_user}\"\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    filename = f\"{dir}/{target_user}.bsky.social_from_{start}_to_{end}.csv\"\n",
    "    \n",
    "    \n",
    "    df.to_csv(filename)\n",
    "\n",
    "# ingest all posts for a specific BlueSky user as a collection of CSVs\n",
    "def ingest_posts_by_user(target_user: str) -> None:\n",
    "    # Retrieve login info from local env\n",
    "    USR = os.getenv('BSY_USR').lower()\n",
    "    KEY = os.getenv('BSY_KEY')\n",
    "    # Instantiate a BlueSky session\n",
    "    cli = Client()\n",
    "    cli.login(USR, KEY)\n",
    "\n",
    "    schema = {'content_id':                []\n",
    "             ,'post_uri':                  []\n",
    "             ,'like_count':                []\n",
    "             ,'quote_count':               []\n",
    "             ,'reply_count':               []\n",
    "             ,'repost_count':              []\n",
    "             ,'post_created_at':           []\n",
    "             ,'text':                      []\n",
    "             ,'tags':                      []\n",
    "             ,'embedded_link_title':       []\n",
    "             ,'embedded_link_description': []\n",
    "             ,'embedded_link_uri':         []\n",
    "             ,'author_username':           []\n",
    "             ,'author_displayname':        []\n",
    "             ,'author_account_created_at': []\n",
    "             }\n",
    "    data = schema \n",
    "    \n",
    "    # Set some control vars for ingestion\n",
    "    pages_remain = True\n",
    "    page_num     = 0\n",
    "    csr          = None\n",
    "    filenum      = 0\n",
    "    \n",
    "    # Iterate through every post in their account's post history\n",
    "    while pages_remain:\n",
    "        \n",
    "        # check if the current file is already \"full\" (larger than 100 MB)\n",
    "        # if it is, stash the current data object as CSV and reset a new empty one\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.memory_usage(deep=True).sum() / (1024*1024) >= 100:\n",
    "            filenum+=1\n",
    "            write_chunk(df, target_user)\n",
    "            data = schema\n",
    "            del df # No need to lock up memory while the next instance of `data` is filling up...\n",
    "        \n",
    "        # Retrieve a paginated post-feed for a specific bluesky user\n",
    "        page_num += 1  \n",
    "        resp      = cli.get_author_feed(target_user, cursor=csr)\n",
    "        feed      = resp.feed\n",
    "        print(f\"Retrieving post data from page {page_num} for user @{target_user}.bsky.social...\", end='\\r')\n",
    "        for item in feed:\n",
    "            # i drink your data! i DRINK IT UP ლಠ益ಠ)ლ\n",
    "            data['content_id'].append(item.post.cid)\n",
    "            data['post_uri'].append(item.post.uri)\n",
    "            data['like_count'].append(item.post.like_count)\n",
    "            data['quote_count'].append(item.post.quote_count)\n",
    "            data['reply_count'].append(item.post.reply_count)\n",
    "            data['repost_count'].append(item.post.repost_count)\n",
    "            '''\n",
    "            We will keep all incoming data as string, with the exception of Timestamps. These \n",
    "            will be converted to \"true\" python timestamps.\n",
    "\n",
    "            We do this so we can leverage pandas' .min() and .max() methods when naming our CSV\n",
    "            file \"chunks\".\n",
    "\n",
    "            Another way to do this would be to only do the conversion in `write_chunk()` and \n",
    "            leave the timestamps as strings. But that would mean:\n",
    "                1. Most likely, these data will be converted to true timestamps downstream anways\n",
    "                2. We would need a str column whose values were always 'UTC' so the timezone information\n",
    "                   is still captured -- that would take extra space for a column whose value will never \n",
    "                   change-- UTC is a common standard timezone for most computer system's internal clocks. \n",
    "            '''\n",
    "            ts = datetime.strptime(item.post.record.created_at, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            ts = pytz.timezone('UTC').localize(ts)\n",
    "            data['post_created_at'].append(ts)   \n",
    "\n",
    "            data['text'].append(item.post.record.text)\n",
    "            data['tags'].append(item.post.record.tags)\n",
    "            # post may or may not have external links\n",
    "            try:\n",
    "                data['embedded_link_title'].append(item.post.record.embed.external.title)\n",
    "            except AttributeError:\n",
    "                data['embedded_link_title'].append('null')\n",
    "            try:\n",
    "                data['embedded_link_description'].append(item.post.record.embed.external.description)\n",
    "            except AttributeError:\n",
    "                data['embedded_link_description'].append('null')\n",
    "            try:\n",
    "                data['embedded_link_uri'].append(item.post.record.embed.external.uri)\n",
    "            except AttributeError:\n",
    "                data['embedded_link_uri'].append('null')\n",
    "            data['author_username'].append(item.post.author.handle)\n",
    "            data['author_displayname'].append(item.post.author.display_name)\n",
    "            \n",
    "            ts = datetime.strptime(item.post.author.created_at, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            ts = pytz.timezone('UTC').localize(ts)\n",
    "            data['author_account_created_at'].append(ts) \n",
    "            \n",
    "        if not resp.cursor:\n",
    "            pages_remain = False # flag to stop ingestion when the final page of posts is reached \n",
    "        csr = resp.cursor        # reset cursor when another page of posts is available\n",
    "        time.sleep(2)            # limit query rate to avoid throttling, etc\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        write_chunk(df, target_user)\n",
    "    print(f\"\\nPost Ingestion for user @{target_user}.bsky.social Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Ingestion for user @politico.com.bsky.social Complete!ky.social...\n"
     ]
    }
   ],
   "source": [
    "ingest_posts_by_user('politico.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Politico'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve login info from local env\n",
    "USR = os.getenv('BSY_USR').lower()\n",
    "KEY = os.getenv('BSY_KEY')\n",
    "# Instantiate a BlueSky session\n",
    "cli = Client()\n",
    "cli.login(USR, KEY)\n",
    "\n",
    "resp = cli.get_author_feed('politico.com')\n",
    "resp.feed[0].post.author.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'foo': [1,2,3], 'bar': ['a', 'b', 'c']}\n",
    "len(pd.DataFrame(data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
